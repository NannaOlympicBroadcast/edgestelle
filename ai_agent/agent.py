"""
AI Agent åˆ†æå¼•æ“ â€” æ•°æ®é©±åŠ¨çš„ IoT æµ‹è¯•æŠ¥å‘Šæ™ºèƒ½è¯Šæ–­ç³»ç»Ÿã€‚

æ ¸å¿ƒç‰¹æ€§:
  - æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰ System Prompt (custom_system_prompt)
  - æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰åˆ†æå·¥ä½œæµ (workflow_steps)
  - æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰é‡ç‚¹å…³æ³¨é¢†åŸŸ (focus_areas)
  - æŒ‡æ ‡ä¸šåŠ¡è¯­ä¹‰ (description) æ³¨å…¥åˆ†æä¸Šä¸‹æ–‡
  - LLM ä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§ä¸ºè§„åˆ™å¼•æ“
"""

import asyncio
import logging
import uuid

from openai import AsyncOpenAI
from sqlalchemy import select, update

from backend.app.config import get_settings
from backend.app.database import async_session
from backend.app.models import TestReport, TestTemplate

logger = logging.getLogger("edgestelle.ai_agent")
settings = get_settings()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  é»˜è®¤ System Prompt (å½“ç”¨æˆ·æœªè‡ªå®šä¹‰æ—¶ä½¿ç”¨)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DEFAULT_SYSTEM_PROMPT = """\
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„åµŒå…¥å¼ç¡¬ä»¶æµ‹è¯•ä¸“å®¶ï¼ŒæœåŠ¡äº EdgeStelle IoT è®¾å¤‡è‡ªåŠ¨åŒ–æµ‹è¯•å¹³å°ã€‚

ä½ çš„èŒè´£æ˜¯ï¼š
1. **æ•°æ®å®¡æŸ¥**ï¼šä»”ç»†å®¡æŸ¥è®¾å¤‡ä¸ŠæŠ¥çš„æ¯ä¸€é¡¹æµ‹è¯•æŒ‡æ ‡å€¼ã€‚
2. **é˜ˆå€¼æ¯”å¯¹**ï¼šå°†å®é™…æ•°æ®ä¸æ¨¡æ¿ä¸­å®šä¹‰çš„é˜ˆå€¼è¿›è¡Œé€é¡¹æ¯”å¯¹ï¼Œåˆ¤æ–­æ˜¯å¦è¶…æ ‡ã€‚
3. **å¼‚å¸¸åˆ†æ**ï¼šå¯¹è¶…å‡ºé˜ˆå€¼çš„æŒ‡æ ‡è¿›è¡Œæ·±åº¦åˆ†æï¼Œæ¨æ–­å¯èƒ½çš„ç¡¬ä»¶æ•…éšœã€å›ºä»¶ç¼ºé™·æˆ–ç¯å¢ƒå› ç´ ã€‚
4. **ç»¼åˆè¯„åˆ†**ï¼šç»™å‡º 0~100 åˆ†çš„ç»¼åˆå¥åº·è¯„åˆ†ã€‚
5. **ä¿®å¤å»ºè®®**ï¼šæä¾›å…·ä½“ã€å¯æ“ä½œçš„æ’æŸ¥å’Œä¿®å¤å»ºè®®ã€‚
"""

# å›ºå®šè¾“å‡ºæ ¼å¼è¦æ±‚ (å§‹ç»ˆè¿½åŠ åˆ° System Prompt å)
OUTPUT_FORMAT_INSTRUCTION = """
## è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºè¯Šæ–­æŠ¥å‘Šï¼š

---

# ğŸ”¬ è®¾å¤‡æµ‹è¯•è¯Šæ–­æŠ¥å‘Š

## ğŸ“Š ç»¼åˆè¯„åˆ†: [XX]/100

## ğŸ“‹ æŒ‡æ ‡æ±‡æ€»

| æŒ‡æ ‡ | å®é™…å€¼ | é˜ˆå€¼ä¸Šé™ | é˜ˆå€¼ä¸‹é™ | çŠ¶æ€ |
|------|--------|----------|----------|------|
| ... | ... | ... | ... | âœ… æ­£å¸¸ / âš ï¸ è­¦å‘Š / âŒ å¼‚å¸¸ |

## âš ï¸ å¼‚å¸¸é¢„è­¦

[é€æ¡åˆ—å‡ºå‘ç°çš„å¼‚å¸¸ï¼Œè¯´æ˜ä¸¥é‡ç¨‹åº¦]

## ğŸ” åŸå› åˆ†æ

[å¯¹æ¯ä¸ªå¼‚å¸¸æŒ‡æ ‡ç»™å‡ºå¯èƒ½åŸå› åˆ†æ]

## ğŸ› ï¸ ä¿®å¤å»ºè®®

[ç»™å‡ºå…·ä½“çš„æ’æŸ¥æ­¥éª¤å’Œä¿®å¤æ–¹æ¡ˆ]

## ğŸ“ æ€»ç»“

[ä¸€æ®µæ€»ç»“æ€§æ–‡å­—]

---

## æ³¨æ„äº‹é¡¹
- å³ä½¿æ‰€æœ‰æŒ‡æ ‡å‡æ­£å¸¸ï¼Œä¹Ÿè¦ç»™å‡ºç»¼åˆè¯„ä»·å’Œé¢„é˜²æ€§å»ºè®®ã€‚
- å¤šä¸ªå¼‚å¸¸ä¹‹é—´å¦‚æœ‰å…³è”ï¼Œåº”ä»ç³»ç»Ÿå±‚é¢ç»¼åˆåˆ†æã€‚
- è¯„åˆ†å‚è€ƒ: 90-100 ä¼˜ç§€, 70-89 è‰¯å¥½, 50-69 è­¦å‘Š, 0-49 ä¸¥é‡ã€‚
"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  åŠ¨æ€ System Prompt ç»„è£…
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def build_system_prompt(analysis_config: dict | None) -> str:
    """
    æ ¹æ®æ¨¡æ¿ä¸­çš„ analysis_config åŠ¨æ€ç»„è£… System Promptã€‚

    ä¼˜å…ˆçº§: custom_system_prompt > DEFAULT_SYSTEM_PROMPT
    å§‹ç»ˆè¿½åŠ : è¾“å‡ºæ ¼å¼æŒ‡ä»¤ + workflow_steps + focus_areas
    """
    config = analysis_config or {}

    # 1. åŸºç¡€è§’è‰² Prompt
    base_prompt = config.get("custom_system_prompt") or DEFAULT_SYSTEM_PROMPT

    parts = [base_prompt.strip()]

    # 2. è¿½åŠ å·¥ä½œæµæ­¥éª¤
    workflow_steps = config.get("workflow_steps")
    if workflow_steps:
        parts.append("\n## è¯Šæ–­å·¥ä½œæµ\n\nè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é¡ºåºæ‰§è¡Œè¯Šæ–­ï¼š\n")
        for step in workflow_steps:
            parts.append(f"- {step}")

    # 3. è¿½åŠ é‡ç‚¹å…³æ³¨é¢†åŸŸ
    focus_areas = config.get("focus_areas")
    if focus_areas:
        parts.append("\n## é‡ç‚¹å…³æ³¨é¢†åŸŸ\n\nè¯·ä¼˜å…ˆåˆ†æä»¥ä¸‹é¢†åŸŸçš„ç›¸å…³æŒ‡æ ‡ï¼š\n")
        for area in focus_areas:
            parts.append(f"- **{area}**")

    # 4. å§‹ç»ˆè¿½åŠ è¾“å‡ºæ ¼å¼æŒ‡ä»¤
    parts.append(OUTPUT_FORMAT_INSTRUCTION)

    return "\n".join(parts)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ä¸Šä¸‹æ–‡æ„å»º (å«æŒ‡æ ‡è¯­ä¹‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def build_analysis_context(template: dict, report: dict) -> str:
    """
    å°†æ¨¡æ¿é˜ˆå€¼ã€æŒ‡æ ‡è¯­ä¹‰å’Œè®¾å¤‡å®æµ‹æ•°æ®æ•´ç†ä¸ºç»“æ„åŒ–ä¸Šä¸‹æ–‡æ–‡æœ¬ã€‚

    æ–°å¢: æ¯ä¸ªæŒ‡æ ‡çš„ description (ä¸šåŠ¡è¯­ä¹‰) ä¼šä½œä¸ºç‹¬ç«‹åˆ—æ³¨å…¥ä¸Šä¸‹æ–‡ã€‚
    """
    lines = []
    lines.append("## æµ‹è¯•æ¨¡æ¿ä¿¡æ¯")
    lines.append(f"- æ¨¡æ¿åç§°: {template.get('name', 'æœªçŸ¥')}")
    lines.append(f"- ç‰ˆæœ¬: {template.get('version', 'æœªçŸ¥')}")
    lines.append("")

    # æ¨¡æ¿ä¸­çš„æŒ‡æ ‡å®šä¹‰ (å« description)
    schema_def = template.get("schema_definition", {})
    template_metrics = {m["name"]: m for m in schema_def.get("metrics", [])}

    lines.append("## è®¾å¤‡ä¸ŠæŠ¥æ•°æ®")
    lines.append(f"- è®¾å¤‡ ID: {report.get('device_id', 'æœªçŸ¥')}")
    lines.append(f"- ä¸ŠæŠ¥æ—¶é—´: {report.get('timestamp', 'æœªçŸ¥')}")
    lines.append("")

    # â”€â”€ æŒ‡æ ‡è¯¦æƒ…è¡¨ (æ–°å¢ "ä¸šåŠ¡å«ä¹‰" åˆ—) â”€â”€
    lines.append("## æŒ‡æ ‡è¯¦æƒ…")
    lines.append("")
    lines.append("| æŒ‡æ ‡ | ä¸šåŠ¡å«ä¹‰ | å•ä½ | å®é™…å€¼ | é˜ˆå€¼ä¸Šé™ | é˜ˆå€¼ä¸‹é™ | æ˜¯å¦è¶…æ ‡ |")
    lines.append("|------|----------|------|--------|----------|----------|----------|")

    results = report.get("results", [])
    for r in results:
        name = r.get("name", "?")
        unit = r.get("unit", "")
        value = r.get("value", "N/A")

        # ä»æ¨¡æ¿å®šä¹‰ä¸­è·å– description
        tmpl_metric = template_metrics.get(name, {})
        desc = tmpl_metric.get("description", "â€”")

        t_max = r.get("threshold_max", tmpl_metric.get("threshold_max", "â€”"))
        t_min = r.get("threshold_min", tmpl_metric.get("threshold_min", "â€”"))

        exceeded = "å¦"
        if t_max not in (None, "â€”") and isinstance(value, (int, float)):
            if value > float(t_max):
                exceeded = "âš ï¸ è¶…ä¸Šé™"
        if t_min not in (None, "â€”") and isinstance(value, (int, float)):
            if value < float(t_min):
                exceeded = "âš ï¸ ä½äºä¸‹é™"

        lines.append(f"| {name} | {desc} | {unit} | {value} | {t_max} | {t_min} | {exceeded} |")

    # å¼‚å¸¸æ‘˜è¦
    anomaly_summary = report.get("anomaly_summary", [])
    if anomaly_summary:
        lines.append("")
        lines.append("## è®¾å¤‡ç«¯å¼‚å¸¸æ‘˜è¦")
        for a in anomaly_summary:
            lines.append(f"- {a}")

    return "\n".join(lines)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  LLM è°ƒç”¨ (åŠ¨æ€ Prompt)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


async def call_llm(system_prompt: str, context: str) -> str:
    """
    è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ API è¿›è¡Œåˆ†æã€‚

    Parameters
    ----------
    system_prompt : str
        åŠ¨æ€ç»„è£…çš„ System Prompt (åŸºäºæ¨¡æ¿ analysis_config)ã€‚
    context : str
        ç»“æ„åŒ–çš„æµ‹è¯•æ•°æ®ä¸Šä¸‹æ–‡ã€‚

    Returns
    -------
    str
        LLM è¿”å›çš„ Markdown è¯Šæ–­æŠ¥å‘Šã€‚
    """
    client = AsyncOpenAI(
        api_key=settings.OPENAI_API_KEY,
        base_url=settings.OPENAI_BASE_URL,
    )

    user_message = f"è¯·åˆ†æä»¥ä¸‹ IoT è®¾å¤‡çš„æµ‹è¯•æ•°æ®ï¼Œå¹¶æŒ‰æ ¼å¼è¾“å‡ºè¯Šæ–­æŠ¥å‘Šï¼š\n\n{context}"

    logger.info("ğŸ¤– æ­£åœ¨è°ƒç”¨ LLM (%s) è¿›è¡Œåˆ†æâ€¦", settings.OPENAI_MODEL)
    logger.debug("ğŸ“ System Prompt é•¿åº¦: %d å­—ç¬¦", len(system_prompt))

    response = await client.chat.completions.create(
        model=settings.OPENAI_MODEL,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message},
        ],
        temperature=0.3,
        max_tokens=2000,
    )

    analysis = response.choices[0].message.content
    logger.info("âœ… LLM åˆ†æå®Œæˆ â€” è¾“å‡º %d å­—ç¬¦", len(analysis))
    return analysis


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  æ ¸å¿ƒå·¥ä½œæµ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


async def analyze_report(report_id: uuid.UUID) -> str | None:
    """
    AI Agent ä¸»æµç¨‹ï¼šè¯»å–æŠ¥å‘Š â†’ æ„å»ºä¸Šä¸‹æ–‡ â†’ åŠ¨æ€ç»„è£… Prompt â†’ LLM åˆ†æ â†’ ç»“æœå­˜åº“ã€‚

    Parameters
    ----------
    report_id : uuid.UUID
        å¾…åˆ†æçš„æŠ¥å‘Š IDã€‚

    Returns
    -------
    str | None
        åˆ†æç»“æœ Markdown æ–‡æœ¬ï¼Œå¤±è´¥è¿”å› Noneã€‚
    """
    logger.info("ğŸ”„ å¼€å§‹åˆ†ææŠ¥å‘Š â€” id=%s", report_id)

    async with async_session() as session:
        # è¯»å–æŠ¥å‘Š
        result = await session.execute(
            select(TestReport).where(TestReport.id == report_id)
        )
        report_obj = result.scalar_one_or_none()
        if report_obj is None:
            logger.error("âŒ æŠ¥å‘Šä¸å­˜åœ¨: %s", report_id)
            return None

        # è¯»å–å…³è”æ¨¡æ¿
        result = await session.execute(
            select(TestTemplate).where(TestTemplate.id == report_obj.template_id)
        )
        template_obj = result.scalar_one_or_none()

        # æ„å»ºæ¨¡æ¿æ•°æ®
        template_data = {
            "name": template_obj.name if template_obj else "æœªçŸ¥æ¨¡æ¿",
            "version": template_obj.version if template_obj else "?",
            "schema_definition": template_obj.schema_definition if template_obj else {},
        }
        report_data = report_obj.report_data

        # â”€â”€ æå– analysis_config â”€â”€
        schema_def = template_data.get("schema_definition", {})
        analysis_config = schema_def.get("analysis_config")

        # â”€â”€ åŠ¨æ€ç»„è£… System Prompt â”€â”€
        system_prompt = build_system_prompt(analysis_config)

        # â”€â”€ æ„å»ºåˆ†æä¸Šä¸‹æ–‡ (å«æŒ‡æ ‡è¯­ä¹‰) â”€â”€
        context = build_analysis_context(template_data, report_data)

        logger.info("ğŸ“‹ analysis_config: %s",
                     "ç”¨æˆ·è‡ªå®šä¹‰" if analysis_config else "ä½¿ç”¨é»˜è®¤")

        # è°ƒç”¨ LLM
        try:
            analysis = await call_llm(system_prompt, context)
        except Exception as e:
            logger.error("âŒ LLM è°ƒç”¨å¤±è´¥: %s", e, exc_info=True)
            analysis = _fallback_analysis(template_data, report_data)

        # ç»“æœå­˜åº“
        await session.execute(
            update(TestReport)
            .where(TestReport.id == report_id)
            .values(ai_analysis=analysis, status="analyzed")
        )
        await session.commit()
        logger.info("ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜ â€” report_id=%s", report_id)

        # â”€â”€ é£ä¹¦é›†æˆ (å¯é€‰) â”€â”€
        try:
            await _push_to_feishu(
                report_id=report_id,
                device_id=report_data.get("device_id", "unknown"),
                analysis=analysis,
                anomaly_summary=report_data.get("anomaly_summary", []),
            )
        except Exception as e:
            logger.warning("âš ï¸ é£ä¹¦æ¨é€å¤±è´¥ (ä¸å½±å“ä¸»æµç¨‹): %s", e)

        return analysis


def _fallback_analysis(template: dict, report: dict) -> str:
    """
    LLM ä¸å¯ç”¨æ—¶çš„ç®€å•è§„åˆ™åˆ†æï¼ˆé™çº§æ–¹æ¡ˆï¼‰ã€‚
    """
    lines = ["# ğŸ”¬ è®¾å¤‡æµ‹è¯•è¯Šæ–­æŠ¥å‘Š (è§„åˆ™å¼•æ“)", ""]
    lines.append("> âš ï¸ LLM æœåŠ¡ä¸å¯ç”¨ï¼Œä»¥ä¸‹ä¸ºåŸºäºé˜ˆå€¼çš„è‡ªåŠ¨åˆ†æã€‚\n")

    schema_def = template.get("schema_definition", {})
    template_metrics = {m["name"]: m for m in schema_def.get("metrics", [])}

    results = report.get("results", [])
    anomalies = []
    total = len(results)
    normal_count = 0

    for r in results:
        name = r.get("name", "?")
        value = r.get("value")
        tmpl = template_metrics.get(name, {})
        t_max = r.get("threshold_max", tmpl.get("threshold_max"))
        t_min = r.get("threshold_min", tmpl.get("threshold_min"))
        desc = tmpl.get("description", "")

        desc_hint = f" ({desc})" if desc else ""

        if t_max is not None and isinstance(value, (int, float)) and value > float(t_max):
            anomalies.append(f"- **{name}**{desc_hint} = {value}{r.get('unit', '')} â€” è¶…å‡ºä¸Šé™ {t_max}")
        elif t_min is not None and isinstance(value, (int, float)) and value < float(t_min):
            anomalies.append(f"- **{name}**{desc_hint} = {value}{r.get('unit', '')} â€” ä½äºä¸‹é™ {t_min}")
        else:
            normal_count += 1

    score = int((normal_count / max(total, 1)) * 100)
    lines.append(f"## ğŸ“Š ç»¼åˆè¯„åˆ†: {score}/100\n")

    if anomalies:
        lines.append("## âš ï¸ å¼‚å¸¸æŒ‡æ ‡\n")
        lines.extend(anomalies)
    else:
        lines.append("## âœ… æ‰€æœ‰æŒ‡æ ‡å‡åœ¨æ­£å¸¸èŒƒå›´\n")

    lines.append("\n## ğŸ“ æ€»ç»“\n")
    lines.append(f"å…±æ£€æµ‹ {total} é¡¹æŒ‡æ ‡ï¼Œ{normal_count} é¡¹æ­£å¸¸ï¼Œ{len(anomalies)} é¡¹å¼‚å¸¸ã€‚")

    return "\n".join(lines)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  é£ä¹¦æ¨é€
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import re


async def _push_to_feishu(
    report_id: uuid.UUID,
    device_id: str,
    analysis: str,
    anomaly_summary: list,
) -> None:
    """
    å°†åˆ†æç»“æœæ¨é€åˆ°é£ä¹¦ (åˆ›å»ºæ–‡æ¡£ + å‘é€å¡ç‰‡)ã€‚

    ä»…åœ¨é£ä¹¦é…ç½®å®Œæ•´æ—¶æ‰§è¡Œï¼Œå¦åˆ™é™é»˜è·³è¿‡ã€‚
    """
    if not settings.FEISHU_APP_ID or not settings.FEISHU_APP_SECRET:
        logger.debug("é£ä¹¦æœªé…ç½®ï¼Œè·³è¿‡æ¨é€")
        return

    from backend.app.integrations.feishu import (
        create_feishu_doc,
        build_alert_card,
        send_message_card,
    )

    # æå–ç»¼åˆè¯„åˆ†
    score_match = re.search(r"ç»¼åˆè¯„åˆ†[:\s]*(\d+)/100", analysis)
    score = score_match.group(0) if score_match else "N/A"

    # 1. åˆ›å»ºé£ä¹¦æ–‡æ¡£
    title = f"EdgeStelle è¯Šæ–­æŠ¥å‘Š â€” {device_id}"
    doc_url = await create_feishu_doc(title, analysis)

    # 2. æ„å»ºå¹¶å‘é€æ¶ˆæ¯å¡ç‰‡
    webui_url = f"{settings.OPENAI_BASE_URL.replace('/v1', '')}"  # fallback
    try:
        from backend.app.config import get_settings as _get_settings
        _s = _get_settings()
        webui_url = f"{_s.FRONTEND_URL}/reports/{report_id}"
    except Exception:
        webui_url = f"http://localhost:5173/reports/{report_id}"

    webhook_url = settings.FEISHU_BOT_WEBHOOK_URL

    # ä¹Ÿå°è¯•ä»æ•°æ®åº“ SystemConfig è¯»å–
    if not webhook_url:
        try:
            from backend.app.database import async_session as _async_session
            from backend.app.models import SystemConfig
            from sqlalchemy import select as _select

            async with _async_session() as session:
                result = await session.execute(
                    _select(SystemConfig).where(SystemConfig.key == "feishu_bot_webhook_url")
                )
                config = result.scalar_one_or_none()
                if config:
                    webhook_url = config.value
        except Exception:
            pass

    if not webhook_url:
        logger.info("ğŸ“„ é£ä¹¦æ–‡æ¡£å·²åˆ›å»º: %s (æœªé…ç½® Webhookï¼Œè·³è¿‡å¡ç‰‡æ¨é€)", doc_url)
        return

    card = build_alert_card(
        device_id=device_id,
        score=score,
        anomaly_summary=anomaly_summary,
        doc_url=doc_url,
        webui_url=webui_url,
    )
    await send_message_card(webhook_url, card)
    logger.info("âœ… é£ä¹¦æ¨é€å®Œæˆ â€” device=%s doc=%s", device_id, doc_url)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MQTT è§¦å‘å›è°ƒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


async def on_new_report(report_id: uuid.UUID, payload: dict):
    """
    ä¾› mqtt_listener æ³¨å†Œçš„å›è°ƒ â€” æ–°æŠ¥å‘Šå…¥åº“åè§¦å‘åˆ†æã€‚
    """
    logger.info("ğŸ”” è§¦å‘ AI åˆ†æ â€” report_id=%s device=%s",
                report_id, payload.get("device_id", "?"))
    try:
        analysis = await analyze_report(report_id)
        if analysis:
            logger.info("ğŸ“„ åˆ†æå®Œæˆï¼Œå‰ 100 å­—ç¬¦:\n%s", analysis[:100])
    except Exception as e:
        logger.error("âŒ AI åˆ†ææµç¨‹å¼‚å¸¸: %s", e, exc_info=True)

